[2023-03-11T09:09:55.535+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: snf_dag.load_emp_table manual__2023-03-11T09:09:47.908869+00:00 [queued]>
[2023-03-11T09:09:55.541+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: snf_dag.load_emp_table manual__2023-03-11T09:09:47.908869+00:00 [queued]>
[2023-03-11T09:09:55.541+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2023-03-11T09:09:55.542+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2023-03-11T09:09:55.542+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2023-03-11T09:09:55.551+0000] {taskinstance.py:1300} INFO - Executing <Task(SnowflakeOperator): load_emp_table> on 2023-03-11 09:09:47.908869+00:00
[2023-03-11T09:09:55.556+0000] {standard_task_runner.py:55} INFO - Started process 446 to run task
[2023-03-11T09:09:55.559+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'snf_dag', 'load_emp_table', 'manual__2023-03-11T09:09:47.908869+00:00', '--job-id', '59', '--raw', '--subdir', 'DAGS_FOLDER/snf_dag.py', '--cfg-path', '/tmp/tmp_b55qdgt']
[2023-03-11T09:09:55.560+0000] {standard_task_runner.py:83} INFO - Job 59: Subtask load_emp_table
[2023-03-11T09:09:55.615+0000] {task_command.py:388} INFO - Running <TaskInstance: snf_dag.load_emp_table manual__2023-03-11T09:09:47.908869+00:00 [running]> on host a2514c64f69a
[2023-03-11T09:09:55.661+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=snf_dag
AIRFLOW_CTX_TASK_ID=load_emp_table
AIRFLOW_CTX_EXECUTION_DATE=2023-03-11T09:09:47.908869+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-03-11T09:09:47.908869+00:00
[2023-03-11T09:09:55.662+0000] {sql.py:254} INFO - Executing: insert into employees values
    (1, 'Vimal', 101, 'Sr Director', 200000, 'Delhi'),
    (2, 'Jeff Dean', 102, 'Vice President', 250000, 'New York'),
    (3, 'Arjun', 103, 'Sr Vice President', 300000, 'London'),
    (4, 'Raghavan', 103, 'Data Architect', 200000, 'Bangalore'),
    (5, 'Paul G', 103, 'Enterprise Architect', 200000, 'California');
[2023-03-11T09:09:55.669+0000] {base.py:73} INFO - Using connection ID 'snowflake_default' for task execution.
[2023-03-11T09:09:56.078+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/snowflake/connector/options.py:108: UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
  "pyarrow", installed_pyarrow_version, pandas_pyarrow_extra

[2023-03-11T09:09:56.269+0000] {base.py:73} INFO - Using connection ID 'snowflake_default' for task execution.
[2023-03-11T09:09:56.270+0000] {connection.py:287} INFO - Snowflake Connector for Python Version: 3.0.1, Python Version: 3.7.16, Platform: Linux-5.15.49-linuxkit-aarch64-with-debian-11.6
[2023-03-11T09:09:56.271+0000] {connection.py:990} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-03-11T09:09:56.271+0000] {connection.py:1007} INFO - Setting use_openssl_only mode to False
[2023-03-11T09:09:56.924+0000] {cursor.py:738} INFO - query: [ALTER SESSION SET autocommit=False]
[2023-03-11T09:09:57.019+0000] {cursor.py:751} INFO - query execution done
[2023-03-11T09:09:57.022+0000] {cursor.py:891} INFO - Number of results in first chunk: 1
[2023-03-11T09:09:57.026+0000] {sql.py:375} INFO - Running statement: insert into employees values
    (1, 'Vimal', 101, 'Sr Director', 200000, 'Delhi'),
    (2, 'Jeff Dean', 102, 'Vice President', 250000, 'New York'),
    (3, 'Arjun', 103, 'Sr Vice President', 300000, 'London'),
    (4, 'Raghavan', 103, 'Data Architect', 200000, 'Bangalore'),
    (5, 'Paul G', 103, 'Enterprise Architect', 200000, 'California');, parameters: None
[2023-03-11T09:09:57.029+0000] {cursor.py:738} INFO - query: [insert into employees values (1, 'Vimal', 101, 'Sr Director', 200000, 'Delhi'), ...]
[2023-03-11T09:09:57.759+0000] {cursor.py:751} INFO - query execution done
[2023-03-11T09:09:57.760+0000] {sql.py:384} INFO - Rows affected: 5
[2023-03-11T09:09:57.761+0000] {snowflake.py:391} INFO - Rows affected: 5
[2023-03-11T09:09:57.761+0000] {snowflake.py:392} INFO - Snowflake query id: 01aadf05-0000-4f6a-0004-9dfe0001513a
[2023-03-11T09:09:57.762+0000] {cursor.py:738} INFO - query: [COMMIT]
[2023-03-11T09:09:57.939+0000] {cursor.py:751} INFO - query execution done
[2023-03-11T09:09:57.939+0000] {cursor.py:891} INFO - Number of results in first chunk: 1
[2023-03-11T09:09:57.940+0000] {connection.py:586} INFO - closed
[2023-03-11T09:09:57.976+0000] {connection.py:589} INFO - No async queries seem to be running, deleting session
[2023-03-11T09:09:58.059+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=snf_dag, task_id=load_emp_table, execution_date=20230311T090947, start_date=20230311T090955, end_date=20230311T090958
[2023-03-11T09:09:58.127+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2023-03-11T09:09:58.145+0000] {taskinstance.py:2578} INFO - 1 downstream tasks scheduled from follow-on schedule check
